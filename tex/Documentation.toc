\contentsline {chapter}{\numberline {1}Introduction}{3}
\contentsline {paragraph}{Virtualization has become a very popular way for IT departments to reduce the amount of equipment they use, while still providing services to their users. Dozens of different companies have dozens of different ways to virtualize, and it should come as a shock to no one that the world\IeC {\textquoteright }s biggest software maker wants a piece of the virtualization pie. In this thesis we\IeC {\textquoteright }ll take a closer look at the issue of virtualization, itself, before we really drill into the features of Hyper-V. While computer technology continues to march forward with smaller, sleeker, more powerful machines, in many ways how we use computers has come full circle. Obviously the computers of today are way more powerful than the computers of the 1950s, but it turns out the way we are using them is harkening back to the early days of computing. Let\IeC {\textquoteright }s take a look at the history of virtualization to see how it all began and look at some of the ways that the world of virtualization has evolved}{3}
\contentsline {section}{\numberline {1.1}What is virtualization}{3}
\contentsline {paragraph}{Virtualization, in its simplest form, is the abstraction of hardware from the software. This can take many different forms. It can be in the form of operating system virtualization such as Hyper-V; presentation virtualization with terminal services; or application virtualization with App-V; and companies like Cisco and Hewlett Packard have network and storage virtualization. Operating system virtualization is the most popular virtualization today. It is not only used on servers but is installed on workstations for doing development and conducting demonstrations. Virtualization can help companies maximize the value of IT investments, decreasing the server hardware footprint, energy consumption, and cost and complexity of managing IT systems while increasing the flexibility of the overall environment. Virtualization also helps IT professionals and developers build systems with the flexibility and intelligence to automatically adjust to changing business conditions by aligning computing resources with strategic objectives.}{4}
\contentsline {section}{\numberline {1.2}What can be virtualized}{4}
\contentsline {section}{\numberline {1.3}Disk IO}{4}
\contentsline {paragraph}{Is the input and output (IO) of data to a hard disk. Disk IO is measured by the number of IO operations per second (IOPS) that can be performed. When planning a Windows Server 2008 Hyper-V environment, it will be critical to provide enough IO performance from your disk subsystem to the host server or servers to support the IO requirements for the host and each virtual machine you implement. When you are implementing a new virtual machine or converting a physical machine to a virtual machine, the virtual machine itself will use the same amount of IO as it did or would have if it were a physical server. Also, the total amount of IO isn\IeC {\textquoteright }t just the sum of the virtual machines; it must also include the IO of the host. While doing this, keep in mind that you will someday add more virtual servers to that host.}{4}
\contentsline {section}{\numberline {1.4}Memory Utilization}{5}
\contentsline {paragraph}{Is how much Random Access Memory (RAM) a system uses for the base operating system as well as for the applications that run on that system. The amount of memory a system uses can go up and down depending on the workload a server is experiencing at any given time. Knowing how much memory your guests use at load and on average will help you determine not only how much memory you will need to purchase for your host systems, but also how many virtual machines you will be able to place on that host.}{5}
\contentsline {section}{\numberline {1.5}Processor Utilization}{5}
\contentsline {paragraph}{Processor utilization is how much throughput your CPU is doing at any given time. Each task or process that runs on a multitasking CPU must share CPU cycles. This is important because if a task is already heavy on the CPU, there is less time for the CPU to work with other processes. With the creation of multicore processors there are more CPU cores available to do the tasks at hand. When you do the analysis of your current machines, pay close attention to the utilization and the type of processors that are in your systems. This will help determine the number of virtual machines that can fit on a host machine.}{5}
\contentsline {section}{\numberline {1.6}Network Utilization}{5}
\contentsline {paragraph}{Is the amount of network usage of a system. This usage is generally expressed as the amount of bandwidth being recorded over a period of time in megabits per second. The network utilization rate is the ratio of current traffic to the maximum traffic that the port can handle. If network utilization rates are high, then the network is busy. If they are low, then the network is idle. If the rate is too high, the result is low transmission speeds. However, when we talk about network utilization as it relates to virtualization, we\IeC {\textquoteright }re talking about multiple virtual machines sharing a single network interface card (NIC). The result is a much more efficient strategy, and one that reduces the amount of network traffic. Even if the real NIC is loaded with all the traffic, the virtualization environment offers you a way to manage network interfaces for each virtual machine you have. This way every machine has its own IP, MAC address, registered into a custom local network inside the virtualization environment.}{6}
\contentsline {section}{\numberline {1.7}The problem}{6}
\contentsline {paragraph}{While there are a lot of virtual machines on a cluster, it admins have a lot of trouble configuring and securing them. Let\IeC {\textquoteright }s take for example a cluster with 1000 virtual machines, it is almost impossible for a company to configure the security for each of them. Of course there are Endpoint security solutions, which gather data in one central point, analyzing the behavior, detect and remove malware. But what about the network security? In a very basic and simple scenario, one IT administrator should configure a security solution on each of the machines, like Windows Defender Firewall. But remember the 1000 machines? Well yes, that is impossible. Another reason why this is impossible and impractical of course is that certain machines need different firewall policies, have different needs, some might not need to be secured, and some might need to be isolated from the rest of the network at one point. There can be testing infrastructures, with complicated network setups, switches, routers etc. Some might say that a simple solution is to manipulate the traffic at the physical outgoing network interface, but that is very impractical. We cannot make the same decision for 1000 machines. We need to configure each firewall in accordance with the demands of each machines. }{6}
\contentsline {section}{\numberline {1.8}The solution}{6}
\contentsline {paragraph}{One solution, a way that can be used even by Endpoint Protection Security software, is to be able to control the network traffic from a single machine, and more concise, the host machine. IT admins would be able to isolate machines, allow traffic from certain machines and to certain machines. Security solutions can follow the malicious traffic from the source (the host machine) through the system and eventually block it without direct intervention into the machine. In the following chapters, I will show you my solution to this and what it can accomplish. I will be helped in the implementation and testing process by Microsoft Windows Hyper-V ecosystem, a virtualization environment developed by Microsoft. Other examples of virtualization environments are VMware, Connectix and Xen.}{7}
\contentsline {chapter}{\numberline {2}Theoretical part}{8}
\contentsline {section}{\numberline {2.1}History of virtualization}{8}
\contentsline {paragraph}{While computer technology continues to march forward with smaller, sleeker, more powerful machines, in many ways how we use computers has come full circle. Obviously the computers of today are way more powerful than the computers of the 1950s, but it turns out the way we are using them is going back to the early days of computing.}{8}
\contentsline {paragraph}{Anyone who has been around computers for a while will quickly recognize that the concept of running a client\IeC {\textquoteright }s session on a server and then displaying the results on the client machine describes the way mainframes work. Let\IeC {\textquoteright }s take a look at the history of virtualization to see how it all began and look at some of the ways that the world of virtualization has evolved.}{8}
\contentsline {section}{\numberline {2.2}Mainframes examples}{8}
\contentsline {paragraph}{The reigning king in the world of virtualization is VMware. Their line of products (including ESX Server and VI3) has led the recent movement toward virtualized IT systems.}{8}
\contentsline {paragraph}{Connectix Corp. was a company that made virtualization software for Windows and Macintosh-based computers. In 2003 Microsoft acquired their virtualization technology and now uses it in their own virtualization products.}{9}
\contentsline {paragraph}{In addition to Hyper-V (the main subject of this book ), there are two other virtualization products from Microsoft out there. While not as grand in scope as Hyper-V, they are still a means of virtualization. Microsoft brings to the virtualization party Virtual PC, Virtual Server, and Hyper-V. }{9}
\contentsline {section}{\numberline {2.3}What is Hyper-V}{9}
\contentsline {paragraph}{Following the launch of Windows Server 2008, Microsoft released Windows Server 2008 Hyper-V, the hypervisor-based virtualization technology that is a role built into 64-bit versions of Windows Server 2008. Hyper-V offers a reliable, scalable, and high-performance virtualization platform that plugs into existing IT infrastructures, enabling users to consolidate some of the most demanding workloads. In addition, the Microsoft System Center product family gives customers a single set of integrated tools to manage physical and virtual resources, helping customers create a more agile and dynamic datacenter. Hyper-V\IeC {\textquoteright }s scalability derives from its support for multiple processors and cores at the host level and improved memory limits at the host and guest level within virtual machines. This enables users to scale their virtualization environment to support a large number of virtual machines within a given host and to take advantage of quick migration for high availability across multiple hosts.}{9}
\contentsline {section}{\numberline {2.4}What is a v-switch}{9}
\contentsline {paragraph}{A \textbf {v-switch}, ( virtual switch more precise ), is a virtual device that give the virtual machines and the host to communicate over network. This type of switches are completely simulating a real swithc, giving a network admin the posibility to create complex routes and networks, faster and easier that working with physical devices. In most cases, a v-switch is used to create communication channels vetween Virtual Machines, and between virtual machines and the host.}{9}
\contentsline {subsection}{\numberline {2.4.1}Networking options}{10}
\contentsline {paragraph}{The \textbf {External} network setting creates a connection to a physical NIC so that guest virtual machines can access the physical network to which that NIC is connected. The \textbf {Internal} setting creates a network that the host and the guest virtual machines can communicate on. The \textbf {Private} network setting creates a network that only virtual machines can communicate on. The main and only difference betweem Internal and Private is that the host machine does not have a NIC in the Private one. Basicly, if you add a NIC of the host in a Private network, it becomes an Internal one. More than likely, if you are mixing production, development, and test workloads on your virtual environments, you will have a mix of external, internal, and private networks.}{10}
\contentsline {subsection}{\numberline {2.4.2}What can be filtered}{10}
\contentsline {paragraph}{A normal firewall, working on a machine, can have access to traffic data at the 7th from the OSI model, and more exactly at the Application Layer. When talking about filtering traffic from a switch, the maximum layer that we can access is layer 4, and more exactly the Transport Layer.}{10}
\contentsline {paragraph}{The difference between the 2 aproaches is that filtring at layer 7 gives you more control over what applications access the network, or what applications are accessed from outside the computer. Layer 7 gives us information like \textbf {Application id} and \textbf {TCP Flow Information}}{10}
\contentsline {subsubsection}{TCP example}{10}
\contentsline {paragraph}{TCP has a well known \textit {handshake} for every connection made. It is a way to syncronize 2 endpoints and let them know how to communicate with each other. The handshake looks like this:}{10}
\contentsline {paragraph}{After this operation, at the operating system level, the TCP connection has been made. This connection is known as a \textbf {TCP Flow}. On a Windows machine, the NDIS network drivers does this, with the help of tcpip.sys driver.}{11}
\contentsline {paragraph}{It is important to notice the fact that when working on Layer 7 as a firewall, you can detect and make a decision about every TCP Flow, without bothering with the handshake. On the other hand, if a firewall wants to filter traffic from the siwtch, it must correlate by itself all the handhake operations to detect a TCP connection.}{11}
\contentsline {subsubsection}{Traffic directions}{11}
\contentsline {paragraph}{At the machine layer, when talking about network traffic we have inbound traffic, and outbound traffic. As their name sais, inbound traffic is the one that comes from outside and outbound traffic is the one that goes out in the network. When speaking about v-swith traffic, there is no inbound and outbound, because the refference object os not a machine anymore, but a switch. For these, there are the terms \textbf {Egress} and \textbf {Ingress}. \textbf {Egress} traffic is the traffic that gets out from the switch, and \textbf {Ingress} is the traffic that goes in the switch. }{12}
\contentsline {section}{\numberline {2.5}Virtualization types}{12}
\contentsline {paragraph}{There are two major types of hypervisors: a monolithic hypervisor and a microkernelized hypervisor. The monolithic hypervisor is installed directly to hardware and holds all third-party tools and drivers required for the Admin VM and guest VMs to function. A microkernelized hypervisor, like the monolithic hypervisor, is installed directly to the hardware but offloads driver management and the virtualization stack to the parent partition}{13}
\contentsline {section}{\numberline {2.6}Hyper-V Partitions}{13}
\contentsline {subsection}{\numberline {2.6.1}VMBus}{13}
\contentsline {section}{\numberline {2.7}Windows Kernel}{13}
\contentsline {subsection}{\numberline {2.7.1}File system drivers}{13}
\contentsline {subsection}{\numberline {2.7.2}Network Drivers(NDIS)}{13}
\contentsline {section}{\numberline {2.8}Network drivers}{13}
\contentsline {subsection}{\numberline {2.8.1}TCP/IP stack}{13}
\contentsline {subsection}{\numberline {2.8.2}Windows Filtering Platform}{13}
\contentsline {subsubsection}{Layer available for filtering}{13}
\contentsline {subsubsection}{Filters}{13}
\contentsline {subsubsection}{Callouts}{13}
\contentsline {chapter}{\numberline {3}Application}{15}
\contentsline {section}{\numberline {3.1}Project description}{15}
\contentsline {section}{\numberline {3.2}Project architecture}{15}
\contentsline {subsection}{\numberline {3.2.1}Kernel mode}{15}
\contentsline {subsubsection}{Wfp Callouts}{15}
\contentsline {subsubsection}{Communication with UM}{15}
\contentsline {subsection}{\numberline {3.2.2}User mode}{15}
\contentsline {subsubsection}{Filters}{15}
\contentsline {subsubsection}{Communication with KM}{16}
